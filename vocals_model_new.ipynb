{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthewmcq/lanternfish/blob/main/vocals_model_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXNq3vyjORTc"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aie-EzaSV05M",
        "outputId": "a90c3a4b-444a-48b2-c5b6-fd99afd889fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "x5EyolaDNrXV"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/lanternfish/Code/')\n",
        "import Utils.Batch.generate_examples\n",
        "import Utils.Batch.batch_data\n",
        "import Utils.Plot\n",
        "import tensorflow as tf\n",
        "# import Models.wavelet_unet\n",
        "import Config as cfg\n",
        "# from Train import train, WaveletLoss\n",
        "import numpy as np\n",
        "import cv2\n",
        "# from Utils.Wavelets import inverseWaveletReshape\n",
        "import Utils.Wavelets\n",
        "# import Utils.Wavelets.inverseWaveletReshape\n",
        "import matplotlib.pyplot as plt\n",
        "import pywt\n",
        "import soundfile as sf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eN8bPhgsRvOv",
        "outputId": "1cfce42b-208d-454a-97ca-49e54a5d8f3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.16.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.17,>=2.16 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.16.2)\n",
            "Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PZJIbufFXAnS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "onutb1nCa-QZ"
      },
      "outputs": [],
      "source": [
        "SR = 44100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O941L1gqOKru"
      },
      "source": [
        "### Dataset Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sqh4n-rJODXo"
      },
      "outputs": [],
      "source": [
        "### DO NOT CHANGE ###\n",
        "MEDLEY2_PATH = 'Datasets/MedleyDB/V2/'\n",
        "MEDLEY1_PATH = 'Datasets/MedleyDB/V1/'\n",
        "TRAIN_PATH =  \"/content/Datasets/TrainingData/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPfIv1lFOUfG"
      },
      "source": [
        "### Set stem type to process\n",
        "Options are: 'vocals', 'drums', 'bass', 'midrange'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wuotU0ZsOfH8"
      },
      "outputs": [],
      "source": [
        "CURR_STEM_TYPE = 'vocals'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S941iQEbOlru"
      },
      "source": [
        "### Preprocessing + Batching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Cbjg57hCOlTO"
      },
      "outputs": [],
      "source": [
        "def preprocess_medleydb(stem_type: str, clean: bool =False, sample_length=65536) -> None:\n",
        "    '''\n",
        "    Preprocess the MedleyDB dataset to generate training data\n",
        "\n",
        "    params:\n",
        "    - stem_type: str, type of stem to split (e.g. vocals, drums, bass, midrange)\n",
        "    - clean: bool, flag to clean the training data\n",
        "\n",
        "    return: None\n",
        "    '''\n",
        "\n",
        "    ## call clean_training_data() first to clean the training data if something goes wrong\n",
        "    if clean:\n",
        "        Utils.Batch.generate_examples.clean_training_data(TRAIN_PATH, stem_type)\n",
        "\n",
        "    ## call generate_examples() to generate the examples\n",
        "    Utils.Batch.generate_examples.generate_data(MEDLEY1_PATH, TRAIN_PATH, stem_type, sample_length) ## -- WORKS!\n",
        "    Utils.Batch.generate_examples.generate_data(MEDLEY2_PATH, TRAIN_PATH, stem_type, sample_length) ## -- WORKS!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Lp71LA_hO2a1"
      },
      "outputs": [],
      "source": [
        "def batch_training_data(level: int = 12, batch_size: int = 8, max_songs: int = 2, max_samples_per_song: int = 10, num_features: int=65536) -> tf.data.Dataset:\n",
        "    '''\n",
        "    Batch the wavelet data for training\n",
        "\n",
        "    params:\n",
        "    - level: int, level of wavelet decomposition\n",
        "    - batch_size: int, number of samples per batch\n",
        "    - max_songs: int, maximum number of songs to include in the batch\n",
        "    - max_samples_per_song: int, maximum number of samples per song\n",
        "\n",
        "    return:\n",
        "    - tf.data.Dataset, batched wavelet data\n",
        "    '''\n",
        "    ## call batch_wavelets() to batch the wavelet data\n",
        "    y_train, y_true, shape = Utils.Batch.batch_data.batch_wavelets_dataset(TRAIN_PATH, CURR_STEM_TYPE, level, batch_size, max_songs, max_samples_per_song, num_features, diff=False)\n",
        "\n",
        "    return y_train, y_true, shape\n",
        "\n",
        "\n",
        "def batch_training_data_debug(level: int = 12, batch_size: int = 8, max_songs: int = 2, max_samples_per_song: int = 10, num_features: int=65536) -> tf.data.Dataset:\n",
        "    '''\n",
        "    Batch the wavelet data for training\n",
        "\n",
        "    params:\n",
        "    - level: int, level of wavelet decomposition\n",
        "    - batch_size: int, number of samples per batch\n",
        "    - max_songs: int, maximum number of songs to include in the batch\n",
        "    - max_samples_per_song: int, maximum number of samples per song\n",
        "\n",
        "    return:\n",
        "    - tf.data.Dataset, batched wavelet data\n",
        "    '''\n",
        "    ## call batch_wavelets() to batch the wavelet data\n",
        "    y_train, y_true, shape = Utils.Batch.batch_data.batch_wavelets_debug(TRAIN_PATH, CURR_STEM_TYPE, level, batch_size, max_songs, max_samples_per_song, num_features, diff=False)\n",
        "\n",
        "    return y_train, y_true, shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "S1uTmFjt4gNg"
      },
      "outputs": [],
      "source": [
        "\n",
        "def inverseWaveletReshape(tensor_coeffs, shape, wavelet_depth):\n",
        "    \"\"\"\n",
        "    Reverse the wavelet transform and downscale the tensor coefficients to match the original shape.\n",
        "\n",
        "    Args:\n",
        "        tensor_coeffs (tf.Tensor): The tensor of wavelet coefficients, with shape (max_features, wavelet_depth + 1).\n",
        "        shape (tuple): The original shape of the waveform.\n",
        "        wavelet_depth (int): The depth of the wavelet decomposition.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of tuples representing the downscaled wavelet coefficients.\n",
        "    \"\"\"\n",
        "    # Convert the tensor to a NumPy array\n",
        "    # coeffs = tensor_coeffs.numpy()\n",
        "    coeffs = tensor_coeffs\n",
        "\n",
        "    # Create a list to store the downscaled coefficients\n",
        "    downscaled_coeffs = []\n",
        "\n",
        "    # Iterate over the wavelet levels\n",
        "    for level in range(wavelet_depth + 1):\n",
        "        # Get the coefficients for the current level\n",
        "        level_coeffs = coeffs[:, level].numpy()\n",
        "        # print(f\"level_coeffs: {level_coeffs.shape}\")\n",
        "        # print(f\"level_coeffs: {level_coeffs.shape}\")\n",
        "        # interval = shape[level][0] // level_coeffs.shape[0]\n",
        "        # replace = level_coeffs[::interval, :]\n",
        "\n",
        "        # print(f\"replace: {replace}\")\n",
        "        # print(f\"replace.shape: {replace.shape}\")\n",
        "\n",
        "\n",
        "        # Reshape the coefficients to match the original shape\n",
        "        # reshaped_coeffs = level_coeffs.reshape(shape[level])\n",
        "        dsize = (shape[level][0], 1)\n",
        "        # print(f\"dsize: {dsize}\")\n",
        "        reshaped_coeffs = cv2.resize(level_coeffs.reshape(1, -1), dsize=dsize, interpolation=cv2.INTER_AREA).flatten()\n",
        "        # print(f\"reshaped_coeffs.shape: {reshaped_coeffs.shape}\")\n",
        "        # print(f\"reshaped_coeffs: {reshaped_coeffs}\")\n",
        "\n",
        "        # Collapse the noisy lower LOD detail and approximation coefficients\n",
        "        # collapsed_coeffs = np.mean(reshaped_coeffs, axis=1)\n",
        "        # collapsed_coeffs = np.median(reshaped_coeffs, axis=1)\n",
        "\n",
        "        # Append the collapsed coefficients to the list\n",
        "        downscaled_coeffs.append(reshaped_coeffs)\n",
        "\n",
        "    # print(f\"downscaled_coeffs: {downscaled_coeffs}\")\n",
        "    # downscaled_coeffs = np.array(downscaled_coeffs).flatten()\n",
        "    return downscaled_coeffs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r08yJk2QxYD"
      },
      "source": [
        "### Get prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jKlHeEhzQwlY"
      },
      "outputs": [],
      "source": [
        "def get_prediction(model, y_train, y_true, shape, model_config):\n",
        "  print(f\"expand dims shape: {tf.expand_dims(y_train[i], axis=0).shape}\")\n",
        "  predict_train_0 = model.predict(tf.expand_dims(y_train[i], axis=0))[0]\n",
        "  predict_true_0 = y_true[i]\n",
        "\n",
        "  print(f\"predict_train_0.shape before reshape: {predict_train_0.shape}\")\n",
        "\n",
        "  predict_train_0 = inverseWaveletReshape(predict_train_0, shape, model_config['wavelet_depth'])\n",
        "  predict_true_0 = inverseWaveletReshape(predict_true_0.numpy(), shape, model_config['wavelet_depth'])\n",
        "\n",
        "  print(f\"predict_train_0.shape aftr reshape: {([len(coef) for coef in predict_train_0])}\")\n",
        "\n",
        "  print(f\"predict_train_0: {(predict_train_0)}\")\n",
        "  print(f\"predict_true_0: {(predict_true_0)}\")\n",
        "\n",
        "  return predict_train_0, predict_true_0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2tTh-PvPKhb"
      },
      "source": [
        "### Generating Audio Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NtA21C1iPPxS"
      },
      "outputs": [],
      "source": [
        "def get_wav_output(predict_train_0, predict_true_0, index):\n",
        "  output = pywt.waverec(predict_train_0, 'haar', axis=-1)\n",
        "  output_true = pywt.waverec(predict_true_0, 'haar', axis=-1)\n",
        "\n",
        "  sf.write(f'test{index}.wav', output, SR)\n",
        "  sf.write(f'true{index}.wav', output_true, SR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLI_qfH5QSdR"
      },
      "source": [
        "### Plot Wavelet Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qWqC2H7xQUix"
      },
      "outputs": [],
      "source": [
        "def plot_wavelet_data(predict_train_0, predict_true_0, model_config):\n",
        "  # Prepare the time axis\n",
        "  time = np.arange(sum([len(coef) for coef in predict_true_0]))\n",
        "\n",
        "  plt.rcParams['figure.figsize'] = (8, 8)\n",
        "  plt.rcParams['font.size'] = 8\n",
        "\n",
        "  # Plot the wavelet coefficients\n",
        "  fig, ax = plt.subplots(model_config['wavelet_depth'] + 1, 1, figsize=(12, 6))\n",
        "\n",
        "  # # Plot the original signal\n",
        "  # start = 0\n",
        "  # for level, coef in enumerate(predict_true_0):\n",
        "  #     ax[0].plot(time[start:start+len(coef)], coef, label=f'Level {level+1}')\n",
        "  #     start += len(coef)\n",
        "  # ax[0].set_title('Original Signal')\n",
        "  # ax[0].set_xlabel('Time')\n",
        "  # ax[0].set_ylabel('Amplitude')\n",
        "  # ax[0].legend()\n",
        "\n",
        "  # Plot the wavelet coefficients\n",
        "  start = 0\n",
        "  for level in range(model_config['wavelet_depth']):\n",
        "      ax[level + 1].plot(time[start:start+len(predict_true_0[-level])], predict_true_0[-level], label='True')\n",
        "      ax[level + 1].plot(time[start:start+len(predict_train_0[-level])], predict_train_0[-level], label='Predicted')\n",
        "      ax[level + 1].set_title(f'Wavelet Level {level + 1}')\n",
        "      ax[level + 1].set_xlabel('Time')\n",
        "      ax[level + 1].set_ylabel(f'Coef Level {level + 1}')\n",
        "      ax[level + 1].legend()\n",
        "      start += len(predict_true_0[-level])\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VNS0XN-O79v"
      },
      "source": [
        "### Main Method - Train and save model\n",
        "Trains model, saves to .keras file, and calls get_prediction()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-h_NkuGrCv_S"
      },
      "outputs": [],
      "source": [
        "@tf.keras.utils.register_keras_serializable()\n",
        "class WaveletUNet(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, num_coeffs, wavelet_depth, batch_size, channels, num_layers, num_init_filters, filter_size, merge_filter_size, l1_reg, l2_reg, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_coeffs = num_coeffs\n",
        "        self.wavelet_depth = wavelet_depth + 1\n",
        "        self.batch_size = batch_size\n",
        "        self.channels = channels\n",
        "        self.num_layers = num_layers\n",
        "        self.num_init_filters = num_init_filters\n",
        "        self.filter_size = filter_size\n",
        "        self.merge_filter_size = merge_filter_size\n",
        "        self.l1_reg = l1_reg\n",
        "        self.l2_reg = l2_reg\n",
        "\n",
        "        self.input_shape = (self.batch_size, self.num_coeffs, self.wavelet_depth)\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        # Extract the necessary arguments from the config dictionary\n",
        "        num_coeffs = config.pop('num_coeffs')\n",
        "        wavelet_depth = config.pop('wavelet_depth')\n",
        "        batch_size = config.pop('batch_size')\n",
        "        channels = config.pop('channels')\n",
        "        num_layers = config.pop('num_layers')\n",
        "        num_init_filters = config.pop('num_init_filters')\n",
        "        filter_size = config.pop('filter_size')\n",
        "        merge_filter_size = config.pop('merge_filter_size')\n",
        "        l1_reg = config.pop('l1_reg')\n",
        "        l2_reg = config.pop('l2_reg')\n",
        "\n",
        "        return cls(\n",
        "            num_coeffs=num_coeffs,\n",
        "            wavelet_depth=wavelet_depth,\n",
        "            batch_size=batch_size,\n",
        "            channels=channels,\n",
        "            num_layers=num_layers,\n",
        "            num_init_filters=num_init_filters,\n",
        "            filter_size=filter_size,\n",
        "            merge_filter_size=merge_filter_size,\n",
        "            l1_reg=l1_reg,\n",
        "            l2_reg=l2_reg,\n",
        "            **config  # Pass any remaining arguments to the constructor\n",
        "        )\n",
        "\n",
        "    # Create an instance of WaveletUNet with the extracted arguments\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            'num_coeffs': self.num_coeffs,\n",
        "            'wavelet_depth': self.wavelet_depth,\n",
        "            'batch_size': self.batch_size,\n",
        "            'channels': self.channels,\n",
        "            'num_layers': self.num_layers,\n",
        "            'num_init_filters': self.num_init_filters,\n",
        "            'filter_size': self.filter_size,\n",
        "            'merge_filter_size': self.merge_filter_size,\n",
        "            'l1_reg': self.l1_reg,\n",
        "            'l2_reg': self.l2_reg\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Create downsampling blocks\n",
        "        self.downsampling_blocks = {}\n",
        "        self.learnable_downsampling_blocks = {}\n",
        "        self.P = {}\n",
        "        self.U = {}\n",
        "        for i in range(self.num_layers):\n",
        "            block_name = f'{i+1}'\n",
        "            num_filters = self.num_init_filters + (self.num_init_filters * i)\n",
        "            self.downsampling_blocks[block_name] = DownsamplingLayer(num_filters, self.filter_size, name=block_name, l1_reg=self.l1_reg, l2_reg=self.l2_reg)\n",
        "            # self.learnable_downsampling_blocks[block_name] = LearnableDownsamplingLayer(num_filters, self.filter_size, name=block_name, l1_reg=self.l1_reg, l2_reg=self.l2_reg)\n",
        "            self.P[block_name] = tf.keras.layers.Conv1D(\n",
        "                num_filters,\n",
        "                3,\n",
        "                activation=None,\n",
        "                padding='same',\n",
        "                name=f'P_{block_name}'\n",
        "            )\n",
        "            self.U[block_name] = tf.keras.layers.Conv1D(\n",
        "                num_filters,\n",
        "                3,\n",
        "                activation=None,\n",
        "                padding='same',\n",
        "                name=f'U_{block_name}'\n",
        "            )\n",
        "\n",
        "        # Create bottle neck\n",
        "        self.bottle_neck = tf.keras.layers.Conv1D(\n",
        "            self.num_init_filters * (self.num_layers + 1),\n",
        "            self.filter_size,\n",
        "            activation='leaky_relu',\n",
        "            padding='same',\n",
        "            name='bottleneck_conv',\n",
        "            kernel_regularizer=tf.keras.regularizers.l1_l2(l1=self.l1_reg, l2=self.l2_reg),\n",
        "            activity_regularizer=tf.keras.regularizers.l1_l2(l1=self.l1_reg, l2=self.l2_reg)\n",
        "        )\n",
        "\n",
        "        # Create upsampling blocks\n",
        "        # self.upsampling_blocks = {}\n",
        "        self.us_conv1d = {}\n",
        "        self.even = {}\n",
        "        self.odd = {}\n",
        "        for i in range(self.num_layers):\n",
        "            block_name = f'{self.num_layers - i}'\n",
        "            num_filters = self.num_init_filters + (self.num_init_filters * (self.num_layers - i - 1))\n",
        "            # out_channels = num_filters // 2\n",
        "\n",
        "            # self.upsampling_blocks[block_name] = LearnableUpsamplingLayer(num_filters, self.merge_filter_size, name=block_name, l1_reg=self.l1_reg, l2_reg=self.l2_reg)\n",
        "\n",
        "            self.us_conv1d[block_name] = tf.keras.layers.Conv1D(\n",
        "                num_filters,\n",
        "                self.merge_filter_size,\n",
        "                activation='leaky_relu',\n",
        "                padding='same',\n",
        "                name=f'us_conv1d_{block_name}',\n",
        "                trainable=True\n",
        "            )\n",
        "            self.even[block_name] = tf.keras.layers.Conv1D(\n",
        "                num_filters,\n",
        "                1,\n",
        "                activation=None,\n",
        "                padding='same',\n",
        "                name=f'even_{block_name}',\n",
        "                trainable=True\n",
        "            )\n",
        "            self.odd[block_name] = tf.keras.layers.Conv1D(\n",
        "                num_filters,\n",
        "                1,\n",
        "                activation=None,\n",
        "                padding='same',\n",
        "                name=f'odd_{block_name}',\n",
        "                trainable=True\n",
        "            )\n",
        "\n",
        "\n",
        "        self.output_conv3 = tf.keras.layers.Conv1D(\n",
        "            1,\n",
        "            1,\n",
        "            activation='tanh',\n",
        "            padding='same',\n",
        "            name='output_conv3',\n",
        "            # kernel_regularizer=tf.keras.regularizers.l1_l2(l1=self.l1_reg, l2=self.l2_reg),\n",
        "            # activity_regularizer=tf.keras.regularizers.l1_l2(l1=self.l1_reg, l2=self.l2_reg)\n",
        "        )\n",
        "        super().build(input_shape)\n",
        "\n",
        "\n",
        "    def call(self, inputs, is_training=True):\n",
        "\n",
        "\n",
        "        current_layer = inputs\n",
        "\n",
        "        full_mix = tf.math.reduce_sum(current_layer, axis=-1)\n",
        "\n",
        "        enc_outputs = list()\n",
        "\n",
        "        # Downsampling path\n",
        "        for i in range(self.num_layers):\n",
        "\n",
        "            block_name = f'{i+1}'\n",
        "\n",
        "            current_layer = self.downsampling_blocks[block_name](current_layer)\n",
        "\n",
        "\n",
        "            # Save for skip connections\n",
        "            enc_outputs.append(current_layer)\n",
        "\n",
        "            # Decimation step\n",
        "            x_even, x_odd = current_layer[:, ::2, :], current_layer[:, 1::2, :]\n",
        "            # print(f\"shape of even: {x_even.shape}\")\n",
        "            # print(f\"shape of odd: {x_odd.shape}\")\n",
        "            d = x_odd - self.P[block_name](x_even)\n",
        "\n",
        "            c = x_even + self.U[block_name](d)\n",
        "\n",
        "            A = 2**(1/2)\n",
        "\n",
        "            c = c * A\n",
        "            d = d * 1/A\n",
        "\n",
        "            current_layer = tf.concat([c, d], axis=-1)\n",
        "\n",
        "\n",
        "        # Bottle neck\n",
        "        current_layer = self.bottle_neck(current_layer)\n",
        "\n",
        "        # Upsampling path\n",
        "        for i in range(self.num_layers):\n",
        "\n",
        "            block_name = f'{self.num_layers - i}'\n",
        "\n",
        "            x_even, x_odd = current_layer[:, :, :-current_layer.shape[-1]//2], current_layer[:, :, -current_layer.shape[-1]//2:]\n",
        "            x_even = self.even[block_name](x_even)\n",
        "            x_odd = self.odd[block_name](x_odd)\n",
        "            # print(f\"shape of even: {x_even.shape}\")\n",
        "            # print(f\"shape of odd: {x_odd.shape}\")\n",
        "\n",
        "            A = 2**(1/2)\n",
        "            x_odd *= A\n",
        "            x_even *= 1/A\n",
        "\n",
        "            # print(f\"shape of u_setp: {u_step.shape}\")\n",
        "            c = x_even - self.U[block_name](x_odd)\n",
        "\n",
        "            d = x_odd + self.P[block_name](c)\n",
        "\n",
        "            # print(f\"shape of d: {d.shape}\")\n",
        "\n",
        "            output = tf.concat([c, d], axis=1)\n",
        "            # print(f\"shape of output: {output.shape}\")\n",
        "\n",
        "            indices = []\n",
        "            num_entries = x_even.shape[1]\n",
        "            num_outputs = 2 * num_entries\n",
        "\n",
        "            for idx in range(num_outputs):\n",
        "                if idx % 2 == 0:\n",
        "                    indices.append(idx // 2)\n",
        "                else:\n",
        "                    indices.append(num_entries + idx // 2)\n",
        "\n",
        "            current_layer = tf.gather(output, indices, axis = 1)\n",
        "\n",
        "            # Get skip connection\n",
        "            skip_conn = enc_outputs[-i-1]\n",
        "\n",
        "            # Pad if necessary\n",
        "            desired_shape = skip_conn.shape\n",
        "\n",
        "            ### NEW CROPPING METHOD -- crop current_layer to match skip_conn\n",
        "            if current_layer.shape[1] != desired_shape[1]:\n",
        "                if current_layer.shape[1] != desired_shape[1]:\n",
        "                    diff = desired_shape[1] - current_layer.shape[1]\n",
        "                    if diff >0:\n",
        "                        pad_start = diff // 2\n",
        "                        pad_end = diff - pad_start\n",
        "                        current_layer = tf.pad(current_layer, [[0, 0], [pad_start, pad_end], [0,0]], mode='SYMMETRIC')\n",
        "                    else:\n",
        "                        diff = -diff\n",
        "                        crop_start = diff // 2\n",
        "                        current_layer = tf.slice(current_layer, [0, crop_start, 0], [-1, desired_shape[1], -1])\n",
        "\n",
        "\n",
        "            # Concatenate with skip connection\n",
        "            current_layer = tf.keras.layers.Concatenate()([current_layer, skip_conn])\n",
        "\n",
        "            conv1d = self.us_conv1d[block_name]\n",
        "            current_layer = conv1d(current_layer)\n",
        "\n",
        "\n",
        "\n",
        "        desired_shape = full_mix.shape\n",
        "\n",
        "        if current_layer.shape[1] != desired_shape[1]:\n",
        "            diff = desired_shape[1] - current_layer.shape[1]\n",
        "            if diff >0:\n",
        "                pad_start = diff // 2\n",
        "                pad_end = diff - pad_start\n",
        "                current_layer = tf.pad(current_layer, [[0, 0], [pad_start, pad_end], [0,0]], mode='SYMMETRIC')\n",
        "            else:\n",
        "                diff = -diff\n",
        "                crop_start = diff // 2\n",
        "                current_layer = tf.slice(current_layer, [0, crop_start, 0], [-1, desired_shape[1], -1])\n",
        "\n",
        "\n",
        "        current_layer = tf.keras.layers.Concatenate()([tf.expand_dims(full_mix, axis=-1), current_layer])\n",
        "\n",
        "        current_layer = self.output_conv3(current_layer)\n",
        "\n",
        "        return current_layer\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class DownsamplingLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_filters, filter_size, l1_reg=0.0, l2_reg=0.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_filters = num_filters\n",
        "        self.filter_size = filter_size\n",
        "        self.l1_reg = l1_reg\n",
        "        self.l2_reg = l2_reg\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.conv = tf.keras.layers.Conv1D(\n",
        "            self.num_filters,\n",
        "            self.filter_size,\n",
        "            activation='leaky_relu',\n",
        "            padding='same',\n",
        "            kernel_regularizer=tf.keras.regularizers.l1_l2(l1=self.l1_reg, l2=self.l2_reg),\n",
        "            activity_regularizer=tf.keras.regularizers.l1_l2(l1=self.l1_reg, l2=self.l2_reg),\n",
        "            name=f'downsampling_conv_{self.num_filters}'\n",
        "        )\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.conv(inputs)\n",
        "        return x\n",
        "\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            'num_filters': self.num_filters,\n",
        "            'filter_size': self.filter_size,\n",
        "            'l1_reg': self.l1_reg,\n",
        "            'l2_reg': self.l2_reg\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnZynBkkqXo4"
      },
      "source": [
        "### 2D Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ydwaJ096C_Q2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjx5xbARqc6I"
      },
      "source": [
        "### CONFIG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SfQVggauDYIX"
      },
      "outputs": [],
      "source": [
        "def cfg():\n",
        "    # Base configuration\n",
        "    model_config = {'num_layers' : 12, # How many U-Net layers\n",
        "                    'filter_size' : 15, # For Wave-U-Net: Filter size of conv in downsampling block\n",
        "                    'merge_filter_size' : 5, # For Wave-U-Net: Filter size of conv in upsampling block\n",
        "                    'num_init_filters': 24, # THIS MUST BE DIVISIBLE BY 4 IF USING DUALWAVELETUNET\n",
        "\n",
        "\n",
        "                    'learning_rate': 1e-4, # determine's the model's learning rate\n",
        "                    'validation_split': 0.2, # determines what % of training data is used for validation\n",
        "                    'channels': 1,\n",
        "                    'num_coeffs': 16384, # Number of audio samples/detail coefficients per input; currently 220500 for 10 sec audio snippets (our equivalent of num_frames from Wave-U-Net)\n",
        "                    'wavelet_depth': 2,\n",
        "                    'batch_size' : 16, # Batch size\n",
        "                    'epochs': 1000,\n",
        "                    'max_songs': 86, # 86 = all songs vox, 84 = all songs bass, 106 = all songs drumkit\n",
        "                    'max_samples_per_song': 700, #\n",
        "\n",
        "                    'l1_reg': 1e-11, # L1 regularization -> sparse\n",
        "                    'l2_reg': 1e-12, # L2 regularization -> non-sparse\n",
        "\n",
        "                    'lambda_vec': [1],\n",
        "                    'lambda_11': 1,\n",
        "                    'lambda_12': 1,\n",
        "                    }\n",
        "\n",
        "    return model_config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS5-9o26qSmT"
      },
      "source": [
        "### Retrain config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8cTAcx8g47hI"
      },
      "outputs": [],
      "source": [
        "def cfg_retrain():\n",
        "    # Base configuration\n",
        "    model_config = {'num_layers' : 12, # How many U-Net layers\n",
        "                    'filter_size' : 15, # For Wave-U-Net: Filter size of conv in downsampling block\n",
        "                    'merge_filter_size' : 5, # For Wave-U-Net: Filter size of conv in upsampling block\n",
        "                    'num_init_filters': 24, # THIS MUST BE DIVISIBLE BY 4 IF USING DUALWAVELETUNET\n",
        "\n",
        "\n",
        "                    'learning_rate': 4e-5, # determine's the model's learning rate\n",
        "                    'validation_split': 0.2, # determines what % of training data is used for validation\n",
        "                    'channels': 1,\n",
        "                    'num_coeffs': 16384, # Number of audio samples/detail coefficients per input; currently 220500 for 10 sec audio snippets (our equivalent of num_frames from Wave-U-Net)\n",
        "                    'wavelet_depth': 2,\n",
        "                    'batch_size' : 32, # Batch size\n",
        "                    'epochs': 1000,\n",
        "                    'max_songs': 86, # 86 = all songs\n",
        "                    'max_samples_per_song': 700, #\n",
        "\n",
        "                    'l1_reg': 1e-12, # L1 regularization -> sparse\n",
        "                    'l2_reg': 1e-11, # L2 regularization -> non-sparse\n",
        "\n",
        "                    'lambda_vec': [1],\n",
        "                    'lambda_11': 1,\n",
        "                    'lambda_12': 1,\n",
        "                    }\n",
        "\n",
        "    return model_config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pTign95qOIA"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "UcBNGZkzYLRs"
      },
      "outputs": [],
      "source": [
        "import soundfile as sf\n",
        "\n",
        "def train(model, model_config, loss, train, val):\n",
        "    es = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=20,\n",
        "        restore_best_weights=True,\n",
        "        start_from_epoch=0\n",
        "    )\n",
        "\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=model_config['learning_rate'])\n",
        "    metrics = [tf.keras.metrics.RootMeanSquaredError(), tf.keras.metrics.MeanSquaredError()]\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        train,\n",
        "        epochs=model_config['epochs'],\n",
        "        validation_data=val,\n",
        "        callbacks=[es]\n",
        "\n",
        "    )\n",
        "    BATCH_PARAMS = (model_config['wavelet_depth'], model_config['batch_size'], 40, 10)\n",
        "\n",
        "\n",
        "    y_train, y_true, shape = batch_training_data_debug(*BATCH_PARAMS)\n",
        "\n",
        "    for i in range(50):\n",
        "        prediction = model.predict(tf.expand_dims(y_train[i], axis=0))[0]\n",
        "        true = np.transpose(y_true[i], (1,0))\n",
        "        a3, d3, d2 = true\n",
        "        sum_true = a3 + d3 + d2\n",
        "\n",
        "        sum_pred = tf.squeeze(prediction, axis=-1)\n",
        "\n",
        "        train = np.transpose(y_train[i], (1,0))\n",
        "        a1, d1, d0 = train\n",
        "        sum_train = a1 + d1 + d0\n",
        "\n",
        "        sf.write(f'/content/drive/MyDrive/lanternfish/Code/examples/{CURR_STEM_TYPE}/train_{i}.wav', sum_train, 22050)\n",
        "        sf.write(f'/content/drive/MyDrive/lanternfish/Code/examples/{CURR_STEM_TYPE}/true_{i}.wav', sum_true, 22050)\n",
        "        sf.write(f'/content/drive/MyDrive/lanternfish/Code/examples/{CURR_STEM_TYPE}/pred_{i}.wav', sum_pred, 22050)\n",
        "\n",
        "    return model\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class WaveletLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, wavelet_level=4, lambda_vec=[10, 1000, 1000], lambda_11=1, lambda_12=0.25, name='wavelet_loss',   l1_reg=0.0, l2_reg=0.0, **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.wavelet_level = wavelet_level\n",
        "        self.lambda_vec = lambda_vec\n",
        "        self.lambda_11 = lambda_11\n",
        "        self.lambda_12 = lambda_12\n",
        "        self.l1_reg = l1_reg\n",
        "        self.l2_reg = l2_reg\n",
        "\n",
        "    # # @tf.function\n",
        "    def call(self, y_true, y_pred):\n",
        "\n",
        "        # Sum the audios along the wavelet_filter dimension for each example in the batch\n",
        "        summed_true = tf.math.reduce_sum(y_true, axis=-1)\n",
        "        summed_pred = tf.math.reduce_sum(y_pred, axis=-1)\n",
        "\n",
        "        # Calculate the mean squared error between the summed audios for each example in the batch\n",
        "        mse = tf.math.reduce_mean(tf.math.square(summed_true - summed_pred))\n",
        "\n",
        "        # Take the mean of the MSE across the batch\n",
        "        return mse\n",
        "\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            'wavelet_level': self.wavelet_level,\n",
        "            'lambda_vec': self.lambda_vec,\n",
        "            'lambda_11': self.lambda_11,\n",
        "            'lambda_12': self.lambda_12,\n",
        "            'l1_reg': self.l1_reg,\n",
        "            'l2_reg': self.l2_reg\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPNEWgtOqQD3"
      },
      "source": [
        "### Main Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UXCtNUEuO-Me"
      },
      "outputs": [],
      "source": [
        "def main_train():\n",
        "\n",
        "    # model_config = cfg.test_saving()\n",
        "    # aggregate_dataset()\n",
        "\n",
        "    model_config = cfg()\n",
        "\n",
        "    ## Set the parameters -- might want to move to Config.py later\n",
        "    WAVELET_DEPTH = model_config['wavelet_depth'] # level of wavelet decomposition\n",
        "    BATCH_SIZE = model_config['batch_size'] # number of samples per batch\n",
        "    MAX_SONGS = model_config['max_songs'] # maximum number of songs to include in the batch\n",
        "    MAX_SAMPLES_PER_SONG = model_config['max_samples_per_song'] # maximum number of samples per song to include in the batch\n",
        "\n",
        "    ## Set the batch parameters, pass to batch_training_data()\n",
        "    BATCH_PARAMS = (WAVELET_DEPTH, BATCH_SIZE, MAX_SONGS, MAX_SAMPLES_PER_SONG)\n",
        "\n",
        "\n",
        "    ## set the batch size and epochs\n",
        "    batch_size = model_config['batch_size']\n",
        "    epochs = model_config['epochs']\n",
        "\n",
        "\n",
        "    model = WaveletUNet(\n",
        "            num_coeffs=model_config['num_coeffs'],\n",
        "            wavelet_depth=model_config['wavelet_depth'],\n",
        "            batch_size=model_config['batch_size'],\n",
        "            channels=model_config['channels'],\n",
        "            num_layers=model_config['num_layers'],\n",
        "            num_init_filters=model_config['num_init_filters'],\n",
        "            filter_size=model_config['filter_size'],\n",
        "            merge_filter_size=model_config['merge_filter_size'],\n",
        "            l1_reg=model_config['l1_reg'],\n",
        "            l2_reg=model_config['l2_reg']\n",
        "        )\n",
        "\n",
        "    # define a dummy input to build the model\n",
        "    model(tf.random.normal(shape=(batch_size, model_config['num_coeffs'], WAVELET_DEPTH+1)))\n",
        "\n",
        "    # print the model summary\n",
        "    model.summary()\n",
        "\n",
        "    dataset, validation_data, shape = batch_training_data(*BATCH_PARAMS)\n",
        "\n",
        "    print(\"y_train shape:\", shape)\n",
        "    loss =  WaveletLoss(wavelet_level=model_config['wavelet_depth'], lambda_vec=model_config['lambda_vec'], lambda_11=model_config['lambda_11'], lambda_12=model_config['lambda_12'], name='wavelet_loss')\n",
        "\n",
        "    ## train the model\n",
        "    model = train(model, model_config, loss, dataset, validation_data)\n",
        "\n",
        "    model_name = f'/content/drive/MyDrive/lanternfish/Code/new_goated_{CURR_STEM_TYPE}_v1.keras'\n",
        "    model.save(model_name)\n",
        "    # model.save('wavelet_unet_model.h5')\n",
        "\n",
        "    loaded_model = tf.keras.models.load_model(model_name)\n",
        "    # loaded_model = tf.keras.models.load_model('wavelet_unet_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7QO29wuqJAr"
      },
      "source": [
        "### retrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IeSVEk_c4vqA"
      },
      "outputs": [],
      "source": [
        "def retrain():\n",
        "\n",
        "    # model_config = cfg.test_saving()\n",
        "    # aggregate_dataset()\n",
        "\n",
        "    model_config = cfg_retrain()\n",
        "\n",
        "    ## Set the parameters -- might want to move to Config.py later\n",
        "    WAVELET_DEPTH = model_config['wavelet_depth'] # level of wavelet decomposition\n",
        "    BATCH_SIZE = model_config['batch_size'] # number of samples per batch\n",
        "    MAX_SONGS = model_config['max_songs'] # maximum number of songs to include in the batch\n",
        "    MAX_SAMPLES_PER_SONG = model_config['max_samples_per_song'] # maximum number of samples per song to include in the batch\n",
        "\n",
        "    ## Set the batch parameters, pass to batch_training_data()\n",
        "    BATCH_PARAMS = (WAVELET_DEPTH, BATCH_SIZE, MAX_SONGS, MAX_SAMPLES_PER_SONG)\n",
        "\n",
        "\n",
        "    ## set the batch size and epochs\n",
        "    batch_size = model_config['batch_size']\n",
        "    epochs = model_config['epochs']\n",
        "\n",
        "    custom_objects = {\n",
        "    'WaveletUNet': WaveletUNet,\n",
        "    'DownsamplingLayer': DownsamplingLayer\n",
        "    }\n",
        "    model = tf.keras.models.load_model(f'/content/drive/MyDrive/lanternfish/Code/new_goated_{CURR_STEM_TYPE}_v1.keras', custom_objects=custom_objects)\n",
        "\n",
        "\n",
        "    # define a dummy input to build the model\n",
        "    model(tf.random.normal(shape=(batch_size, model_config['num_coeffs'], WAVELET_DEPTH+1)))\n",
        "\n",
        "    # print the model summary\n",
        "    model.summary()\n",
        "\n",
        "    dataset, validation_data, shape = batch_training_data(*BATCH_PARAMS)\n",
        "\n",
        "    print(\"y_train shape:\", shape)\n",
        "    loss =  WaveletLoss(wavelet_level=model_config['wavelet_depth'], lambda_vec=model_config['lambda_vec'], lambda_11=model_config['lambda_11'], lambda_12=model_config['lambda_12'], name='wavelet_loss')\n",
        "\n",
        "    ## train the model\n",
        "    model = train(model, model_config, loss, dataset, validation_data)\n",
        "\n",
        "    model_name = f'/content/drive/MyDrive/lanternfish/Code/new_goated_{CURR_STEM_TYPE}_v1_RETRAIN.keras'\n",
        "    model.save(model_name)\n",
        "    # model.save('wavelet_unet_model.h5')\n",
        "\n",
        "    loaded_model = tf.keras.models.load_model(model_name)\n",
        "    # loaded_model = tf.keras.models.load_model('wavelet_unet_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hRCCz7HRvClk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PQlXPf5Pjfb"
      },
      "source": [
        "### Main Method - Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wHHETWC7cNh2"
      },
      "outputs": [],
      "source": [
        "def main_load():\n",
        "\n",
        "  # model_config = cfg.test_saving()\n",
        "  model_config = cfg()\n",
        "\n",
        "  ## Set the parameters -- might want to move to Config.py later\n",
        "  WAVELET_DEPTH = model_config['wavelet_depth'] # level of wavelet decomposition\n",
        "  BATCH_SIZE = model_config['batch_size'] # number of samples per batch\n",
        "  MAX_SONGS = model_config['max_songs'] # maximum number of songs to include in the batch\n",
        "  MAX_SAMPLES_PER_SONG = model_config['max_samples_per_song'] # maximum number of samples per song to include in the batch\n",
        "\n",
        "  ## Set the batch parameters, pass to batch_training_data()\n",
        "  BATCH_PARAMS = (WAVELET_DEPTH, BATCH_SIZE, MAX_SONGS, MAX_SAMPLES_PER_SONG)\n",
        "\n",
        "  ## batch the data for medleyDB\n",
        "  # preprocess_medleydb(CURR_STEM_TYPE, clean=True)\n",
        "\n",
        "  ## set the batch size and epochs\n",
        "  batch_size = model_config['batch_size']\n",
        "  epochs = model_config['epochs']\n",
        "\n",
        "  ## test that generate_pairs() works\n",
        "  y_train, y_true, shape = batch_training_data(*BATCH_PARAMS)\n",
        "\n",
        "  print(\"y_train shape:\", shape)\n",
        "\n",
        "  ## check the loss function for all zeros\n",
        "  zero_train = tf.zeros_like(y_train)\n",
        "\n",
        "\n",
        "  wavelet_loss = WaveletLoss(\n",
        "      wavelet_level=model_config['wavelet_depth'],\n",
        "      lambda_vec=model_config['lambda_vec'],\n",
        "      lambda_11=model_config['lambda_11'],\n",
        "      lambda_12=model_config['lambda_12'],\n",
        "  )\n",
        "\n",
        "  ## check default loss:\n",
        "  loss = WaveletLoss( wavelet_level=model_config['wavelet_depth'], lambda_vec=model_config['lambda_vec'], lambda_11=model_config['lambda_11'], lambda_12=model_config['lambda_12'], name='wavelet_loss')\n",
        "  print(\"Default Loss with regularization:\", loss(y_true, y_train))\n",
        "  print(\"Default Loss (All zeros):\", loss(y_true, zero_train))\n",
        "\n",
        "  ## define the model\n",
        "  model = Models.wavelet_unet.WaveletUNet(\n",
        "      num_coeffs=model_config['num_coeffs'],\n",
        "      wavelet_depth=model_config['wavelet_depth'],\n",
        "      batch_size=model_config['batch_size'],\n",
        "      channels=1,\n",
        "      num_layers=model_config['num_layers'],\n",
        "      num_init_filters=model_config['num_init_filters'],\n",
        "      filter_size=model_config['filter_size'],\n",
        "      merge_filter_size=model_config['merge_filter_size'],\n",
        "      l1_reg=model_config['l1_reg'],\n",
        "      l2_reg=model_config['l2_reg']\n",
        "      )\n",
        "\n",
        "  # define a dummy input to build the model\n",
        "  model(tf.random.normal(shape=(batch_size, model_config['num_coeffs'], WAVELET_DEPTH+1)))\n",
        "\n",
        "  # print the model summary\n",
        "  model.summary()\n",
        "  ## train the model\n",
        "  model = train(model, wavelet_loss, y_train, y_true, epochs, batch_size)\n",
        "\n",
        "  model_name = f'wavelet_unet_model_nif{model_config[\"num_init_filters\"]}_filter{model_config[\"filter_size\"]}_layers{model_config[\"num_layers\"]}.keras'\n",
        "  model.save(model_name)\n",
        "  # model.save('wavelet_unet_model.h5')\n",
        "\n",
        "  # loaded_model = tf.keras.models.load_model(model_name)\n",
        "  # loaded_model = tf.keras.models.load_model('wavelet_unet_model.h5')\n",
        "\n",
        "  for i in range(10):\n",
        "    predict_train_0, predict_true_0 = get_prediction(model, y_train, y_true, shape)\n",
        "    plot_wavelet_data(predict_train_0, predict_true_0, model_config)\n",
        "    get_wav_output(predict_train_0, predict_true_0, i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1rPyq6bPH-v"
      },
      "source": [
        "### Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YHsDSzW570_K"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "def unzip_to_colab():\n",
        "    zip_dir = f'/content/drive/MyDrive/lanternfish/Code/Datasets/TrainingData/{CURR_STEM_TYPE}.zip'\n",
        "    extract_base_dir = '/content/Datasets/TrainingData/'\n",
        "\n",
        "    os.makedirs(extract_base_dir, exist_ok=True)\n",
        "\n",
        "    with zipfile.ZipFile(zip_dir, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_base_dir)\n",
        "\n",
        "    print(\"Unzipping to Colab storage completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAwDpGFbkicc",
        "outputId": "ea635c59-2e1c-4ad0-d530-9c2e069fd7b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping to Colab storage completed.\n"
          ]
        }
      ],
      "source": [
        "# unzip_to_colab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b1weM-KDPfsD",
        "outputId": "3f3b3b1d-5afd-4975-cd3f-dffd3ab833ea"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"wavelet_u_net\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"wavelet_u_net\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " 1 (\u001b[38;5;33mDownsamplingLayer\u001b[0m)                 ?                                      \u001b[38;5;34m1,104\u001b[0m \n",
              "\n",
              " P_1 (\u001b[38;5;33mConv1D\u001b[0m)                          ?                                      \u001b[38;5;34m1,752\u001b[0m \n",
              "\n",
              " U_1 (\u001b[38;5;33mConv1D\u001b[0m)                          ?                                      \u001b[38;5;34m1,752\u001b[0m \n",
              "\n",
              " 2 (\u001b[38;5;33mDownsamplingLayer\u001b[0m)                 ?                                     \u001b[38;5;34m34,608\u001b[0m \n",
              "\n",
              " P_2 (\u001b[38;5;33mConv1D\u001b[0m)                          ?                                      \u001b[38;5;34m6,960\u001b[0m \n",
              "\n",
              " U_2 (\u001b[38;5;33mConv1D\u001b[0m)                          ?                                      \u001b[38;5;34m6,960\u001b[0m \n",
              "\n",
              " 3 (\u001b[38;5;33mDownsamplingLayer\u001b[0m)                 ?                                    \u001b[38;5;34m103,752\u001b[0m \n",
              "\n",
              " P_3 (\u001b[38;5;33mConv1D\u001b[0m)                          ?                                     \u001b[38;5;34m15,624\u001b[0m \n",
              "\n",
              " U_3 (\u001b[38;5;33mConv1D\u001b[0m)                          ?                                     \u001b[38;5;34m15,624\u001b[0m \n",
              "\n",
              " 4 (\u001b[38;5;33mDownsamplingLayer\u001b[0m)                 ?                                    \u001b[38;5;34m207,456\u001b[0m \n",
              "\n",
              " P_4 (\u001b[38;5;33mConv1D\u001b[0m)                          ?                                     \u001b[38;5;34m27,744\u001b[0m \n",
              "\n",
              " U_4 (\u001b[38;5;33mConv1D\u001b[0m)                          ?                                     \u001b[38;5;34m27,744\u001b[0m \n",
              "\n",
              " 5 (\u001b[38;5;33mDownsamplingLayer\u001b[0m)                 ?                                    \u001b[38;5;34m345,720\u001b[0m \n",
              "\n",
              " P_5 (\u001b[38;5;33mConv1D\u001b[0m)                          ?                                     \u001b[38;5;34m43,320\u001b[0m \n",
              "\n",
              " U_5 (\u001b[38;5;33mConv1D\u001b[0m)                          ?                                     \u001b[38;5;34m43,320\u001b[0m \n",
              "\n",
              " 6 (\u001b[38;5;33mDownsamplingLayer\u001b[0m)                 ?                                    \u001b[38;5;34m518,544\u001b[0m \n",
              "\n",
              " P_6 (\u001b[38;5;33mConv1D\u001b[0m)                          ?                                     \u001b[38;5;34m62,352\u001b[0m \n",
              "\n",
              " U_6 (\u001b[38;5;33mConv1D\u001b[0m)                          ?                                     \u001b[38;5;34m62,352\u001b[0m \n",
              "\n",
              " 7 (\u001b[38;5;33mDownsamplingLayer\u001b[0m)                 ?                                    \u001b[38;5;34m725,928\u001b[0m \n",
              "\n",
              " P_7 (\u001b[38;5;33mConv1D\u001b[0m)                          ?                                     \u001b[38;5;34m84,840\u001b[0m \n",
              "\n",
              " U_7 (\u001b[38;5;33mConv1D\u001b[0m)                          ?                                     \u001b[38;5;34m84,840\u001b[0m \n",
              "\n",
              " 8 (\u001b[38;5;33mDownsamplingLayer\u001b[0m)                 ?                                    \u001b[38;5;34m967,872\u001b[0m \n",
              "\n",
              " P_8 (\u001b[38;5;33mConv1D\u001b[0m)                          ?                                    \u001b[38;5;34m110,784\u001b[0m \n",
              "\n",
              " U_8 (\u001b[38;5;33mConv1D\u001b[0m)                          ?                                    \u001b[38;5;34m110,784\u001b[0m \n",
              "\n",
              " 9 (\u001b[38;5;33mDownsamplingLayer\u001b[0m)                 ?                                  \u001b[38;5;34m1,244,376\u001b[0m \n",
              "\n",
              " P_9 (\u001b[38;5;33mConv1D\u001b[0m)                          ?                                    \u001b[38;5;34m140,184\u001b[0m \n",
              "\n",
              " U_9 (\u001b[38;5;33mConv1D\u001b[0m)                          ?                                    \u001b[38;5;34m140,184\u001b[0m \n",
              "\n",
              " 10 (\u001b[38;5;33mDownsamplingLayer\u001b[0m)                ?                                  \u001b[38;5;34m1,555,440\u001b[0m \n",
              "\n",
              " P_10 (\u001b[38;5;33mConv1D\u001b[0m)                         ?                                    \u001b[38;5;34m173,040\u001b[0m \n",
              "\n",
              " U_10 (\u001b[38;5;33mConv1D\u001b[0m)                         ?                                    \u001b[38;5;34m173,040\u001b[0m \n",
              "\n",
              " 11 (\u001b[38;5;33mDownsamplingLayer\u001b[0m)                ?                                  \u001b[38;5;34m1,901,064\u001b[0m \n",
              "\n",
              " P_11 (\u001b[38;5;33mConv1D\u001b[0m)                         ?                                    \u001b[38;5;34m209,352\u001b[0m \n",
              "\n",
              " U_11 (\u001b[38;5;33mConv1D\u001b[0m)                         ?                                    \u001b[38;5;34m209,352\u001b[0m \n",
              "\n",
              " 12 (\u001b[38;5;33mDownsamplingLayer\u001b[0m)                ?                                  \u001b[38;5;34m2,281,248\u001b[0m \n",
              "\n",
              " P_12 (\u001b[38;5;33mConv1D\u001b[0m)                         ?                                    \u001b[38;5;34m249,120\u001b[0m \n",
              "\n",
              " U_12 (\u001b[38;5;33mConv1D\u001b[0m)                         ?                                    \u001b[38;5;34m249,120\u001b[0m \n",
              "\n",
              " bottleneck_conv (\u001b[38;5;33mConv1D\u001b[0m)              ?                                  \u001b[38;5;34m2,695,992\u001b[0m \n",
              "\n",
              " us_conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)                 ?                                    \u001b[38;5;34m829,728\u001b[0m \n",
              "\n",
              " even_12 (\u001b[38;5;33mConv1D\u001b[0m)                      ?                                     \u001b[38;5;34m45,216\u001b[0m \n",
              "\n",
              " odd_12 (\u001b[38;5;33mConv1D\u001b[0m)                       ?                                     \u001b[38;5;34m45,216\u001b[0m \n",
              "\n",
              " us_conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)                 ?                                    \u001b[38;5;34m697,224\u001b[0m \n",
              "\n",
              " even_11 (\u001b[38;5;33mConv1D\u001b[0m)                      ?                                     \u001b[38;5;34m38,280\u001b[0m \n",
              "\n",
              " odd_11 (\u001b[38;5;33mConv1D\u001b[0m)                       ?                                     \u001b[38;5;34m38,280\u001b[0m \n",
              "\n",
              " us_conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)                 ?                                    \u001b[38;5;34m576,240\u001b[0m \n",
              "\n",
              " even_10 (\u001b[38;5;33mConv1D\u001b[0m)                      ?                                     \u001b[38;5;34m31,920\u001b[0m \n",
              "\n",
              " odd_10 (\u001b[38;5;33mConv1D\u001b[0m)                       ?                                     \u001b[38;5;34m31,920\u001b[0m \n",
              "\n",
              " us_conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)                  ?                                    \u001b[38;5;34m466,776\u001b[0m \n",
              "\n",
              " even_9 (\u001b[38;5;33mConv1D\u001b[0m)                       ?                                     \u001b[38;5;34m26,136\u001b[0m \n",
              "\n",
              " odd_9 (\u001b[38;5;33mConv1D\u001b[0m)                        ?                                     \u001b[38;5;34m26,136\u001b[0m \n",
              "\n",
              " us_conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)                  ?                                    \u001b[38;5;34m368,832\u001b[0m \n",
              "\n",
              " even_8 (\u001b[38;5;33mConv1D\u001b[0m)                       ?                                     \u001b[38;5;34m20,928\u001b[0m \n",
              "\n",
              " odd_8 (\u001b[38;5;33mConv1D\u001b[0m)                        ?                                     \u001b[38;5;34m20,928\u001b[0m \n",
              "\n",
              " us_conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)                  ?                                    \u001b[38;5;34m282,408\u001b[0m \n",
              "\n",
              " even_7 (\u001b[38;5;33mConv1D\u001b[0m)                       ?                                     \u001b[38;5;34m16,296\u001b[0m \n",
              "\n",
              " odd_7 (\u001b[38;5;33mConv1D\u001b[0m)                        ?                                     \u001b[38;5;34m16,296\u001b[0m \n",
              "\n",
              " us_conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)                  ?                                    \u001b[38;5;34m207,504\u001b[0m \n",
              "\n",
              " even_6 (\u001b[38;5;33mConv1D\u001b[0m)                       ?                                     \u001b[38;5;34m12,240\u001b[0m \n",
              "\n",
              " odd_6 (\u001b[38;5;33mConv1D\u001b[0m)                        ?                                     \u001b[38;5;34m12,240\u001b[0m \n",
              "\n",
              " us_conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)                  ?                                    \u001b[38;5;34m144,120\u001b[0m \n",
              "\n",
              " even_5 (\u001b[38;5;33mConv1D\u001b[0m)                       ?                                      \u001b[38;5;34m8,760\u001b[0m \n",
              "\n",
              " odd_5 (\u001b[38;5;33mConv1D\u001b[0m)                        ?                                      \u001b[38;5;34m8,760\u001b[0m \n",
              "\n",
              " us_conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)                  ?                                     \u001b[38;5;34m92,256\u001b[0m \n",
              "\n",
              " even_4 (\u001b[38;5;33mConv1D\u001b[0m)                       ?                                      \u001b[38;5;34m5,856\u001b[0m \n",
              "\n",
              " odd_4 (\u001b[38;5;33mConv1D\u001b[0m)                        ?                                      \u001b[38;5;34m5,856\u001b[0m \n",
              "\n",
              " us_conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)                  ?                                     \u001b[38;5;34m51,912\u001b[0m \n",
              "\n",
              " even_3 (\u001b[38;5;33mConv1D\u001b[0m)                       ?                                      \u001b[38;5;34m3,528\u001b[0m \n",
              "\n",
              " odd_3 (\u001b[38;5;33mConv1D\u001b[0m)                        ?                                      \u001b[38;5;34m3,528\u001b[0m \n",
              "\n",
              " us_conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)                  ?                                     \u001b[38;5;34m23,088\u001b[0m \n",
              "\n",
              " even_2 (\u001b[38;5;33mConv1D\u001b[0m)                       ?                                      \u001b[38;5;34m1,776\u001b[0m \n",
              "\n",
              " odd_2 (\u001b[38;5;33mConv1D\u001b[0m)                        ?                                      \u001b[38;5;34m1,776\u001b[0m \n",
              "\n",
              " us_conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                  ?                                      \u001b[38;5;34m5,784\u001b[0m \n",
              "\n",
              " even_1 (\u001b[38;5;33mConv1D\u001b[0m)                       ?                                        \u001b[38;5;34m600\u001b[0m \n",
              "\n",
              " odd_1 (\u001b[38;5;33mConv1D\u001b[0m)                        ?                                        \u001b[38;5;34m600\u001b[0m \n",
              "\n",
              " output_conv3 (\u001b[38;5;33mConv1D\u001b[0m)                 ?                                         \u001b[38;5;34m26\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " 1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DownsamplingLayer</span>)                 ?                                      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,104</span> \n",
              "\n",
              " P_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                          ?                                      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,752</span> \n",
              "\n",
              " U_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                          ?                                      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,752</span> \n",
              "\n",
              " 2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DownsamplingLayer</span>)                 ?                                     <span style=\"color: #00af00; text-decoration-color: #00af00\">34,608</span> \n",
              "\n",
              " P_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                          ?                                      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,960</span> \n",
              "\n",
              " U_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                          ?                                      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,960</span> \n",
              "\n",
              " 3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DownsamplingLayer</span>)                 ?                                    <span style=\"color: #00af00; text-decoration-color: #00af00\">103,752</span> \n",
              "\n",
              " P_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                          ?                                     <span style=\"color: #00af00; text-decoration-color: #00af00\">15,624</span> \n",
              "\n",
              " U_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                          ?                                     <span style=\"color: #00af00; text-decoration-color: #00af00\">15,624</span> \n",
              "\n",
              " 4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DownsamplingLayer</span>)                 ?                                    <span style=\"color: #00af00; text-decoration-color: #00af00\">207,456</span> \n",
              "\n",
              " P_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                          ?                                     <span style=\"color: #00af00; text-decoration-color: #00af00\">27,744</span> \n",
              "\n",
              " U_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                          ?                                     <span style=\"color: #00af00; text-decoration-color: #00af00\">27,744</span> \n",
              "\n",
              " 5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DownsamplingLayer</span>)                 ?                                    <span style=\"color: #00af00; text-decoration-color: #00af00\">345,720</span> \n",
              "\n",
              " P_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                          ?                                     <span style=\"color: #00af00; text-decoration-color: #00af00\">43,320</span> \n",
              "\n",
              " U_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                          ?                                     <span style=\"color: #00af00; text-decoration-color: #00af00\">43,320</span> \n",
              "\n",
              " 6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DownsamplingLayer</span>)                 ?                                    <span style=\"color: #00af00; text-decoration-color: #00af00\">518,544</span> \n",
              "\n",
              " P_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                          ?                                     <span style=\"color: #00af00; text-decoration-color: #00af00\">62,352</span> \n",
              "\n",
              " U_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                          ?                                     <span style=\"color: #00af00; text-decoration-color: #00af00\">62,352</span> \n",
              "\n",
              " 7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DownsamplingLayer</span>)                 ?                                    <span style=\"color: #00af00; text-decoration-color: #00af00\">725,928</span> \n",
              "\n",
              " P_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                          ?                                     <span style=\"color: #00af00; text-decoration-color: #00af00\">84,840</span> \n",
              "\n",
              " U_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                          ?                                     <span style=\"color: #00af00; text-decoration-color: #00af00\">84,840</span> \n",
              "\n",
              " 8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DownsamplingLayer</span>)                 ?                                    <span style=\"color: #00af00; text-decoration-color: #00af00\">967,872</span> \n",
              "\n",
              " P_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                          ?                                    <span style=\"color: #00af00; text-decoration-color: #00af00\">110,784</span> \n",
              "\n",
              " U_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                          ?                                    <span style=\"color: #00af00; text-decoration-color: #00af00\">110,784</span> \n",
              "\n",
              " 9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DownsamplingLayer</span>)                 ?                                  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,244,376</span> \n",
              "\n",
              " P_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                          ?                                    <span style=\"color: #00af00; text-decoration-color: #00af00\">140,184</span> \n",
              "\n",
              " U_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                          ?                                    <span style=\"color: #00af00; text-decoration-color: #00af00\">140,184</span> \n",
              "\n",
              " 10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DownsamplingLayer</span>)                ?                                  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,555,440</span> \n",
              "\n",
              " P_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                         ?                                    <span style=\"color: #00af00; text-decoration-color: #00af00\">173,040</span> \n",
              "\n",
              " U_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                         ?                                    <span style=\"color: #00af00; text-decoration-color: #00af00\">173,040</span> \n",
              "\n",
              " 11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DownsamplingLayer</span>)                ?                                  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,901,064</span> \n",
              "\n",
              " P_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                         ?                                    <span style=\"color: #00af00; text-decoration-color: #00af00\">209,352</span> \n",
              "\n",
              " U_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                         ?                                    <span style=\"color: #00af00; text-decoration-color: #00af00\">209,352</span> \n",
              "\n",
              " 12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DownsamplingLayer</span>)                ?                                  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,281,248</span> \n",
              "\n",
              " P_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                         ?                                    <span style=\"color: #00af00; text-decoration-color: #00af00\">249,120</span> \n",
              "\n",
              " U_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                         ?                                    <span style=\"color: #00af00; text-decoration-color: #00af00\">249,120</span> \n",
              "\n",
              " bottleneck_conv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              ?                                  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,695,992</span> \n",
              "\n",
              " us_conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 ?                                    <span style=\"color: #00af00; text-decoration-color: #00af00\">829,728</span> \n",
              "\n",
              " even_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      ?                                     <span style=\"color: #00af00; text-decoration-color: #00af00\">45,216</span> \n",
              "\n",
              " odd_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                       ?                                     <span style=\"color: #00af00; text-decoration-color: #00af00\">45,216</span> \n",
              "\n",
              " us_conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 ?                                    <span style=\"color: #00af00; text-decoration-color: #00af00\">697,224</span> \n",
              "\n",
              " even_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      ?                                     <span style=\"color: #00af00; text-decoration-color: #00af00\">38,280</span> \n",
              "\n",
              " odd_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                       ?                                     <span style=\"color: #00af00; text-decoration-color: #00af00\">38,280</span> \n",
              "\n",
              " us_conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 ?                                    <span style=\"color: #00af00; text-decoration-color: #00af00\">576,240</span> \n",
              "\n",
              " even_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      ?                                     <span style=\"color: #00af00; text-decoration-color: #00af00\">31,920</span> \n",
              "\n",
              " odd_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                       ?                                     <span style=\"color: #00af00; text-decoration-color: #00af00\">31,920</span> \n",
              "\n",
              " us_conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                  ?                                    <span style=\"color: #00af00; text-decoration-color: #00af00\">466,776</span> \n",
              "\n",
              " even_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                       ?                                     <span style=\"color: #00af00; text-decoration-color: #00af00\">26,136</span> \n",
              "\n",
              " odd_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                        ?                                     <span style=\"color: #00af00; text-decoration-color: #00af00\">26,136</span> \n",
              "\n",
              " us_conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                  ?                                    <span style=\"color: #00af00; text-decoration-color: #00af00\">368,832</span> \n",
              "\n",
              " even_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                       ?                                     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,928</span> \n",
              "\n",
              " odd_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                        ?                                     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,928</span> \n",
              "\n",
              " us_conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                  ?                                    <span style=\"color: #00af00; text-decoration-color: #00af00\">282,408</span> \n",
              "\n",
              " even_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                       ?                                     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,296</span> \n",
              "\n",
              " odd_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                        ?                                     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,296</span> \n",
              "\n",
              " us_conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                  ?                                    <span style=\"color: #00af00; text-decoration-color: #00af00\">207,504</span> \n",
              "\n",
              " even_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                       ?                                     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,240</span> \n",
              "\n",
              " odd_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                        ?                                     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,240</span> \n",
              "\n",
              " us_conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                  ?                                    <span style=\"color: #00af00; text-decoration-color: #00af00\">144,120</span> \n",
              "\n",
              " even_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                       ?                                      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,760</span> \n",
              "\n",
              " odd_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                        ?                                      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,760</span> \n",
              "\n",
              " us_conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                  ?                                     <span style=\"color: #00af00; text-decoration-color: #00af00\">92,256</span> \n",
              "\n",
              " even_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                       ?                                      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,856</span> \n",
              "\n",
              " odd_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                        ?                                      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,856</span> \n",
              "\n",
              " us_conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                  ?                                     <span style=\"color: #00af00; text-decoration-color: #00af00\">51,912</span> \n",
              "\n",
              " even_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                       ?                                      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,528</span> \n",
              "\n",
              " odd_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                        ?                                      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,528</span> \n",
              "\n",
              " us_conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                  ?                                     <span style=\"color: #00af00; text-decoration-color: #00af00\">23,088</span> \n",
              "\n",
              " even_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                       ?                                      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,776</span> \n",
              "\n",
              " odd_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                        ?                                      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,776</span> \n",
              "\n",
              " us_conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                  ?                                      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,784</span> \n",
              "\n",
              " even_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                       ?                                        <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> \n",
              "\n",
              " odd_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                        ?                                        <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> \n",
              "\n",
              " output_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 ?                                         <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,002,218\u001b[0m (72.49 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,002,218</span> (72.49 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,002,218\u001b[0m (72.49 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,002,218</span> (72.49 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(TensorSpec(shape=(16384, 3), dtype=tf.float32, name=None), TensorSpec(shape=(16384, 3), dtype=tf.float32, name=None))\n",
            "(TensorSpec(shape=(16384, 3), dtype=tf.float32, name=None), TensorSpec(shape=(16384, 3), dtype=tf.float32, name=None))\n",
            "(TensorSpec(shape=(16384, 3), dtype=tf.float32, name=None), TensorSpec(shape=(16384, 3), dtype=tf.float32, name=None))\n",
            "y_train shape: [(4096,), (4096,), (8192,)]\n",
            "Epoch 1/1000\n",
            "\u001b[1m2008/2008\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 135ms/step - loss: 0.0053 - mean_squared_error: 0.0043 - root_mean_squared_error: 0.0626 - val_loss: 0.0030 - val_mean_squared_error: 0.0025 - val_root_mean_squared_error: 0.0503\n",
            "Epoch 2/1000\n",
            "\u001b[1m2008/2008\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 113ms/step - loss: 0.0029 - mean_squared_error: 0.0032 - root_mean_squared_error: 0.0563 - val_loss: 0.0027 - val_mean_squared_error: 0.0033 - val_root_mean_squared_error: 0.0573\n",
            "Epoch 3/1000\n",
            "\u001b[1m1936/2008\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 110ms/step - loss: 0.0026 - mean_squared_error: 0.0032 - root_mean_squared_error: 0.0569"
          ]
        }
      ],
      "source": [
        "main_train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPZ6CqL8iJnl"
      },
      "outputs": [],
      "source": [
        "retrain()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "LnZynBkkqXo4",
        "_PQlXPf5Pjfb"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}